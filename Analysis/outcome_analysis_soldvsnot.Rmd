---
title: Outcome Analysis of the Sold-Vs-Not Design
author: Jake Bowers
date: '`r format(Sys.Date(), "%B %d, %Y")`'
fontsize: 11pt
geometry: margin=1in
graphics: yes
indent: false
bibliography:
 - ../refs.bib
biblio-style: authoryear-comp
output:
 pdf_document:
 toc: true
 number_sections: true
 fig_caption: yes
 fig_height: 4
 fig_width: 4
 latex_engine: xelatex
 keep_tex: true
 citation_package: biblatex
 md_extensions: +raw_attribute
---

<!-- NOTE: Adjust for baseline crime covariates within set because of large variability across pharmacies in baseline crime. We do this because we cannot match people within set since much of our outcome data is from people not interviewed in 2017. We would be matching on outcomes if we were not careful.-->


```{r setup, echo=FALSE, include=FALSE, cache=FALSE}
library(here)
source(here::here("Analysis", "rmarkdownsetup.R"))
library(estimatr)
library(tidyverse)
library(optmatch)
library(coin)
library(RItools)
```

```{r loaddat}
load(here::here("Data", "finaldat.rda"), verbose = TRUE)
load(here::here("Data", "wrkdat.rda"), verbose = TRUE)
load(here::here("Analysis", "match_data_prep.rda"), verbose = TRUE)
load(here::here("Analysis", "design_soldvsnot.rda"), verbose = TRUE)
```

# Analyses Registered

We registered the following analyses and research designs in
<https://osf.io/sxe8q> and will submit differences from the planned analyses
there, too.

## Data Setup for the Analyses

Not all outcome variables are available in endline survey. See the
`pap_soldvsnot.Rmd` for more details.


| Hypothesis | Outcome | Variable(s) |
|------------ | -------- | ---------------|
| H1 | Neighbors' crime victimization in the last 12 months  |  vic12 |
| H2 |Neighbors' insecurity perceptions. Country and neighborhood | c_sec_i and n_sec_i |
| H3 | Existence of "bocas" in the neighborhood  | boca1_i |
| H4 | Social Disorder Index  | social_dis |
| H5 | Neighbors' insertion in neighborhood  | activities_index  |
| H6 | Law's perceived of impact on public security  | ps_impact_i  |
| H7 | Law's perceived of impact on drug trafficking | dt_impact_i  |


```{r listvars}
regoutcomes <- c("n_sec_i", "c_sec_i", "vic12_i", "dt_impact_i", "ps_impact_i", "boca1_i", "social_dis", "activities_index")
regcovs <- c("ideol_si_i", "educ_i", "sex_i", "age_i", "robb_2016", "vrobb_2016") ## ,"n_sec_i" this will be used later  at pharmacy/neighborhood  level
regdesignvars <- c("id", "Q56", "treat", "ronda", "ph_type")
```

We want the versions of the variable without imputation for missing values

```{r}
## Checking the relationship between ph_type and treat
with(dat17p, table(soldvsnot17, ph_type, exclude = c()))

## finaldat includes both 2017 and 2018 and is at the individual level
with(finaldat, table(treat, ph_type, exclude = c()))

## This is the outcome data
fdat18i <- finaldat %>%
  dplyr::select(one_of(c(regdesignvars, regoutcomes, regcovs))) %>%
  filter(ronda == 2018) %>%
  mutate_if(is.character, as.numeric)

## Since we do not have the same people in 2017 and 2018, we do covariance
## adjustment either by: ## (1) the rebar method (following Sales and Hansen)
## and/or lin approach using indivi level data and (2) more simply just using the
## phramacy level data. The idea is that a difference score might have more
## statistical power, but we don't observe the same people twice.

replace_NA_0 <- function(x) {
  ifelse(x %in% c(88, 99), NA, x)
}
## Make all 88 and 99 responses into NA
outdat3 <- fdat18i %>%
  dplyr::select(-c("id", "age_i")) %>%
  mutate_all(replace_NA_0)
stopifnot(sum(is.na(outdat3$boca1_i)) == 288) ## make sure to preserve missings
outdat3$id <- fdat18i$id
outdat3$age_i <- fdat18i$age_i
## How much missing data is there?
outdat3 %>% summarise_all(~ sum(is.na(.)))
##  vrobb_2016 and robb_2016 are all missing because they are not recorded for the  2018 subjects. They are pharmacy  level.
##  Leaving them here as placeholders. Otherwise very little missing data.
```

Now merge the pharmacy level design info onto the individual level data

```{r}
stopifnot(all.equal(names(parms1_res$fm_p),row.names(dat17p)))
dat17p$parms1_fm_p <- parms1_res$fm_p

designdat_p <- dat17p %>% dplyr::select(c(
  "Q56", "parms1_fm_p", "soldvsnot17", "ph_type",
  "n_sec_i_mean", "robb_2016_mean", "vrobb_2016_mean"
))

## Two pharmacies (the placebos) were dropped
stopifnot(length(unique(designdat_p$Q56)) == 58)
stopifnot(unique(designdat_p$ph_type) != 5)

outdat4 <- inner_join(outdat3, designdat_p)
stopifnot(isTRUE(all.equal(sort(unique(designdat_p$Q56)), sort(unique(outdat4$Q56)))))
outdat4 %>% summarise_all(~ sum(is.na(.)))
dim(outdat4)
## Dropped 6 non-selling pharmacies. (60 indivs)
dim(outdat3)

## Remove non-selling pharmacies dropped during the design-search process
##  Remove variables that are all  missing
outdat5 <- outdat4 %>%
  filter(!is.na(parms1_fm_p)) %>%
  dplyr::select(-c("robb_2016", "vrobb_2016")) %>%
  ungroup()
dim(outdat5)
```

A quick check to ensure  that  we don't have too  much  missing  data.

```{r}
## Do we need to worry about means (maybe)
regcovs1 <- c(grep("robb", regcovs, value = TRUE, invert = TRUE), "robb_2016_mean", "vrobb_2016_mean", "n_sec_i_mean")
outdat5 %>%
  dplyr::select(all_of(regoutcomes)) %>%
  summarize_all(~ length(unique(.)))
outdat5 %>%
  dplyr::select(all_of(regcovs1)) %>%
  summarize_all(~ length(unique(.)))
```

### Checking heterogeneity within set across individuals

No strong relationships between the types of people living in a place and
whether that place had a pharmacy selling marijuana conditional on set. Here,
checking this relationship allowing for non-linear relationships between
education and age and treatment status.

```{r}
library(splines)
xb_i <- balanceTest(soldvsnot17~ns(educ_i,3)+sex_i+ns(age_i,3)+robb_2016_mean+vrobb_2016_mean+ideol_si_i+strata(parms1_fm_p)+cluster(Q56),data=outdat5,p.adjust.method="holm")
xb_i$results[,,"parms1_fm_p"]
xb_i$overall["parms1_fm_p",]

lm_i <- lm_robust(soldvsnot17~ns(educ_i,3)+sex_i+ns(age_i,3)+robb_2016_mean+vrobb_2016_mean+ideol_si_i,fixed_effects=~parms1_fm_p,cluster=Q56,data=outdat5)
thef <- lm_i$proj_fstatistic
p_thef <- pf(thef["value"], df1 = thef["numdf"], df2 = thef["dendf"], lower.tail = FALSE)
p_thef
```

## Does treatment assignment relate to missingness?

No evidence against the idea that missingness on outcomes is random within set.

```{r}
outdat5 %>%
  dplyr::select(all_of(regoutcomes)) %>%
  summarize_all(~ sum(is.na(.)))

missing_outcome_vars0 <- sapply(outdat5[,regoutcomes],function(x){ any(is.na(x))
    })
missing_outcome_vars <- names(missing_outcome_vars0[missing_outcome_vars0])

outdat5 <- outdat5 %>%
    mutate(across(one_of(missing_outcome_vars),~as.numeric(is.na(.)),.names="missing_{col}"))

missing_test_i <- balanceTest(soldvsnot17~missing_dt_impact_i+missing_ps_impact_i+missing_boca1_i+strata(parms1_fm_p)+cluster(Q56),data=outdat5,p.adjust.method="none")
missing_test_i$results[,,"parms1_fm_p"]
missing_test_i$overall["parms1_fm_p",]
```


## Estimating average effects and testing the weak null of no effects


### Tests of of the weak null combined with estimates of the ATE

First, we do the simple thing --- estimate the ATE and test the weak null of no effects under asymptotic assumptions.

```{r unadj_est}
## Get cluster size and condition on it just to avoid bias as described by
## Aronow and Middleton using the general approach from Lin --- mean centering
## the covariate within block.
outdat5 <- outdat5 %>% group_by(Q56) %>% mutate(n_clus=n()) %>% ungroup()

summary(outdat5[,regoutcomes])

unadj_fn <- function(ynm){
    thedat <- outdat5 %>% filter(!is.na(!!rlang::sym(ynm))) %>% group_by(Q56) %>%
        mutate(n_clus=n()) %>%  ungroup()
    thedat <- thedat %>% group_by(parms1_fm_p) %>%
        mutate(all_same_n=length(unique(n_clus)),n_clus_c=n_clus - mean(n_clus),valid_block=length(unique(soldvsnot17))>1) %>%
        filter(valid_block) %>% droplevels() %>% ungroup()
    if(all(thedat$all_same_n!=1)){
            fmla <- paste(ynm,"~soldvsnot17*n_clus_c",sep="")
    } else {
    fmla <- paste(ynm,"~soldvsnot17",sep="")
    }
    mod <- lm_robust(as.formula(fmla),data=thedat,fixed_effects=~parms1_fm_p,clusters=Q56)
    res <- tidy(mod)  %>% filter(term=="soldvsnot17")
    res$n_clus_used <- length(unique(thedat$n_clus))
    return(res)
}

## unadj_fn("boca1_i")
## unadj_fn(regoutcomes[1])

unadj_coefs_lst <- lapply(regoutcomes,unadj_fn)
unadj_coefs <- bind_rows(unadj_coefs_lst)
unadj_coefs
```

```{r print_unadj_est}
kableExtra::kable(unadj_coefs)
```


```{r naive_est}
## The simple version with the full sample and no statistical adjustment: Mostly
## to learn about power loss and bias reduction from our matched design:

## A function that estimates the effects without the matched design.
simp_fn<- function(ynm){
    thedat <- outdat4 %>% filter(!is.na(!!rlang::sym(ynm))) %>% group_by(Q56) %>%
        mutate(n_clus=n()) %>%  ungroup()
    thedat <- thedat %>% mutate(n_clus_c=n_clus - mean(n_clus)) %>% droplevels() %>% ungroup()
    fmla <- paste(ynm,"~soldvsnot17*n_clus_c",sep="")
    mod <- lm_robust(as.formula(fmla),data=thedat,clusters=Q56)
    res <- tidy(mod)  %>% filter(term=="soldvsnot17")
    res$n_clus_used <- length(unique(thedat$n_clus))
    return(res)
}

simp_coefs_lst <- lapply(regoutcomes,simp_fn)
simp_coefs <- bind_rows(simp_coefs_lst)
simp_coefs
```

Looks like we had more bias that mattered for some outcomes more so that
others: social_dis, and vic12_i stand out as showin much larger
 post-adjustment differences.

```{r print_simp_est}
kableExtra::kable(simp_coefs)
```


```{r mlm_versions, warning=FALSE}

left_join(select(unadj_coefs,estimate,std.error,outcome,p.value),select(simp_coefs,estimate,std.error,outcome,p.value),by="outcome")

## Also try a multilevel model for those more familiar with that approach.
library(lme4)
library(lmerTest)

## A function that estimates the effects without the matched design.
lmer_fn<- function(ynm){
    thedat <- outdat5 %>% filter(!is.na(!!rlang::sym(ynm)))
    fmla <- paste(ynm,"~(1|parms1_fm_p:Q56) + (1|Q56)+soldvsnot17",sep="")
    mod <-
        lmer(as.formula(fmla),data=thedat) #,control=lmerControl(optimizer="bobyqa"))
    res0 <- summary(mod)$coefficients
    res0_ci <- confint(mod)
    res1 <-  data.frame(term=row.names(res0),estimate=res0[,"Estimate"],std.error=res0[,"Std. Error"],
        "statistic"=res0[,"t value"],p.value=res0[,5],conf.low=res0_ci["soldvsnot17",1],conf.high=res0_ci["soldvsnot17",2],outcome=ynm)
    res <- res1  %>% filter(term=="soldvsnot17")
    return(res)
}

lmer_coefs_lst <- lapply(regoutcomes,lmer_fn)
lmer_coefs <- bind_rows(lmer_coefs_lst)
lmer_coefs
```

Compare the two different approaches

```{r compare_mods}
## No real substantive differences
unadj_mods <- left_join(select(unadj_coefs,estimate,outcome,p.value,conf.low,conf.high),
    select(lmer_coefs,estimate,outcome,p.value,conf.low,conf.high),by="outcome",suffix=c(".lm",".lmer"))

kableExtra::kable(unadj_mods %>% select(outcome,estimate.lm,estimate.lmer,p.value.lm,p.value.lmer,conf.low.lm,conf.high.lm,
        conf.low.lmer,conf.high.lmer))
```


As a check on the preceding, do this at the level of the pharmacy:

```{r pharmacy_level}

outdat5p <- outdat5 %>% group_by(Q56) %>%
    summarize(across(one_of(c("soldvsnot17",regoutcomes)),mean,na.rm=TRUE),n_clus=n())
outdat6p <- left_join(outdat5p,dat17p[,c("Q56","parms1_fm_p")],by="Q56")
stopifnot(nrow(outdat5p)==nrow(outdat6p))

unadj_fn_p <- function(ynm){
    thedat <- outdat6p %>% filter(!is.na(!!rlang::sym(ynm)))
    thedat <- thedat %>% group_by(parms1_fm_p) %>% mutate(n_uniq_sets =
        n(),n_clus_c=n_clus - mean(n_clus)) %>%
        filter(n_uniq_sets>1) %>% droplevels()
    fmla <- paste(ynm,"~soldvsnot17*n_clus_c",sep="")
    mod <- lm_robust(as.formula(fmla),data=thedat,fixed_effects=~parms1_fm_p)
    res <- tidy(mod)  %>% filter(term=="soldvsnot17")
    res$n_clus_used <- length(unique(thedat$n_clus))
    return(res)
}

unadj_fn_p("boca1_i")
unadj_fn_p(regoutcomes[1])

unadj_coefs_p_lst <- lapply(regoutcomes,unadj_fn_p)
unadj_coefs_p <- bind_rows(unadj_coefs_p_lst)
unadj_coefs_p

```


```{r print_unadj_coefs_p}
kableExtra::kable(unadj_coefs_p)
```


Now checking with covariance adjustment:

```{r}

adj_fn <- function(ynm){
    thedat <- outdat5 %>% filter(!is.na(!!rlang::sym(ynm))) %>% group_by(Q56) %>%
        mutate(n_clus=n()) %>%  ungroup()
    thedat <- thedat %>% group_by(parms1_fm_p) %>%
        mutate(all_same_n=length(unique(n_clus)),n_clus_c=n_clus - mean(n_clus),
            ideol_c = ideol_si_i - mean(ideol_si_i,na.rm=TRUE),
            educ_c = educ_i - mean(educ_i,na.rm=TRUE),
            sex_c = sex_i - mean(sex_i,na.rm=TRUE),
            age_c = age_i - mean(age_i,na.rm=TRUE),
            valid_block=length(unique(soldvsnot17))>1) %>%
        filter(valid_block) %>% droplevels() %>% ungroup()
    thedat$ideol_c_NA <- as.numeric(is.na(thedat$ideol_c))
    thedat$ideol_c_imp <- ifelse(is.na(thedat$ideol_c),0,thedat$ideol_c)
    fmla <- paste(ynm,"~soldvsnot17*(n_clus_c+ideol_c_imp+ideol_c_NA+educ_c+sex_c+age_c)",sep="")
    mod <- lm_robust(as.formula(fmla),data=thedat,fixed_effects=~parms1_fm_p,clusters=Q56)
    res <- tidy(mod)  %>% filter(term=="soldvsnot17")
    res$n_clus_used <- length(unique(thedat$n_clus))
    return(res)
}

## adj_fn("boca1_i")
##adj_fn(regoutcomes[1])

adj_coefs_lst <- lapply(regoutcomes,adj_fn)
adj_coefs <- bind_rows(adj_coefs_lst)
adj_coefs
```

```{r print_adj_coefs}
kableExtra::kable(adj_coefs)
```


```{r}
unadj_coefs$approach <- "lm indiv"
lmer_coefs$approach <- "lmer indiv"
unadj_coefs_p$approach <- "lm pharm"
adj_coefs$approach <- "lm covadj indiv"

all_unadj <- bind_rows(unadj_coefs,lmer_coefs,unadj_coefs_p,adj_coefs)
all_unadj$outcome_n <- as.numeric(as.factor(all_unadj$outcome))
all_unadj$approach_n <- as.numeric(as.factor(all_unadj$approach)) - 1
all_unadj$outcome_n_yvals <- all_unadj$outcome_n + all_unadj$approach_n/5

g <- ggplot(all_unadj,aes(x=estimate,y=approach))+
    geom_pointrange(aes(xmin=conf.low,xmax=conf.high),shape=21,alpha=.8)+
    geom_vline(xintercept=0,color="dark gray")+
    facet_wrap(~outcome,scales="free")+
    theme_bw()
```

All approaches agree.

```{r}
print(g)
```


## Test for all outcomes

Checking to see if a more powerful test would reveal any effects. Simplify the
hypothesis to a hypothesis of no effects for *any* outcome (other than
`boca1_i`).

```{r}

outdat6p$soldvsnot17F <- factor(outdat6p$soldvsnot17)

with(outdat6p %>% filter(!is.na(boca1_i)),table(soldvsnot17,parms1_fm_p,exclude=c()))

multi_outcome_fmla <- as.formula(paste(paste(regoutcomes[!(regoutcomes %in% c("boca1_i"))],collapse="+"),"~soldvsnot17F|parms1_fm_p",sep=""))

multi_outcome_test_p <- independence_test(multi_outcome_fmla,data=outdat6p)
multi_outcome_test_perm_p <- independence_test(multi_outcome_fmla,data=outdat6p,distribution=approximate())

multi_outcome_test_p
multi_outcome_test_perm_p

## Checking for whether we lose power because of strange distributions. Using a
## rank-based test
outdat6p <- outdat6p %>% mutate(across(one_of(regoutcomes),rank,.names="rank_{col}"))

multi_outcome_test_rank_p <- independence_test(multi_outcome_fmla,data=outdat6p,
                      ytrafo=function(data){ trafo(data, numeric_trafo = rank_trafo) })
multi_outcome_test_rank_perm_p <- independence_test(multi_outcome_fmla,data=outdat6p,
                      ytrafo=function(data){ trafo(data, numeric_trafo = rank_trafo) },
    distribution=approximate())

multi_outcome_test_rank_p
multi_outcome_test_rank_perm_p

```

# Sensitivity Analysis

Since we have no strong effects, relationships where a test of the null
hypothesis of no effects passes the  $p<.05$ threshold, we do not do any
sensitivity analysis.

# References







